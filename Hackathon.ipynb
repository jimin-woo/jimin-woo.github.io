{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Hackathon.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimin-woo/jimin-woo.github.io/blob/main/Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTudLZ-vSkjy"
      },
      "source": [
        "# 필요한 모듈 import \n",
        "\n",
        "from glob import glob\n",
        "import re as re\n",
        "import os as os\n",
        "import json as _json\n",
        "import os.path as path\n",
        "import sys\n",
        "\n",
        "\n",
        "import soundfile as sf\n",
        "import utils as utils\n",
        "import random as _random\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from random import shuffle as shuffle\n",
        "from importlib import import_module as import_module\n",
        "from functools import wraps\n",
        "from python_speech_features import mfcc\n",
        "import time\n",
        "import scipy.io.wavfile as wav\n",
        "import numpy as np\n",
        "from six.moves import xrange as range\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "import pandas as pd\n",
        "import random as random\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import pickle as _pickle\n",
        "import os.path as _path\n",
        "from random import shuffle as _shuffle\n",
        "from importlib import import_module as _import_module\n",
        "import numpy as _np\n",
        "\n",
        "import librosa\n",
        "# 너무 많이 발생하는 경고들을 제거\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
        "\n",
        "from pykospacing import spacing\n",
        "import numpy as np\n",
        "import re\n",
        "from pykospacing import spacing\n",
        "from hanspell import spell_checker\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfYAMRNuSkj0"
      },
      "source": [
        "# 맞춤법, 띄어쓰기, 특수기호 정제를 위한 설치\n",
        "\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV912lKiSkj1"
      },
      "source": [
        "# 텍스트 전처리 함수\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "INITIALS = list(\"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\")\n",
        "\"char list: Hangul initials (초성)\"\n",
        "\n",
        "\n",
        "\n",
        "MEDIALS = list(\"ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ\")\n",
        "\"char list: Hangul medials (중성)\"\n",
        "\n",
        "\n",
        "\n",
        "FINALS = list(\"∅ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ\")\n",
        "\"char list: Hangul finals (종성).\"\n",
        "\n",
        "\n",
        "\n",
        "SPACE_TOKEN = \" \"\n",
        "LABELS = sorted({SPACE_TOKEN}.union(INITIALS).union(MEDIALS).union(FINALS))\n",
        "\n",
        "\"char list: All CTC labels.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def check_syllable(char):\n",
        "  return 0xAC00 <= ord(char) <= 0xD7A3\n",
        "\n",
        "\n",
        "\n",
        "def split_syllable(char):\n",
        "  assert check_syllable(char)\n",
        "  diff = ord(char) - 0xAC00\n",
        "  _m = diff % 28\n",
        "  _d = (diff - _m) // 28\n",
        "  return (INITIALS[_d // 21], MEDIALS[_d % 21], FINALS[_m])\n",
        "\n",
        "\n",
        "\n",
        "def preprocess(str):\n",
        "  result = \"\"\n",
        "  for char in re.sub(\"\\\\s+\", SPACE_TOKEN, str.strip()):\n",
        "    if char == SPACE_TOKEN:\n",
        "      result += SPACE_TOKEN\n",
        "    elif check_syllable(char):\n",
        "      result += \"\".join(split_syllable(char))\n",
        "  return result\n",
        "\n",
        "\n",
        "def join_syllable(char_list):\n",
        "  num = 0xAC00 + 28 * 21 * (INITIALS.index(char_list[0])) + 28 * (MEDIALS.index(char_list[1])) + (FINALS.index(char_list[2]))\n",
        "  s1 = chr(num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2WALxZeSkj2"
      },
      "source": [
        "# 음성데이터 전처리 함수\n",
        "\n",
        "import numpy as _np\n",
        "from scipy.signal import resample_poly as _resample_poly\n",
        "from python_speech_features import mfcc as _mfcc\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "\n",
        "def mfcc(audio, samplerate, n_features, **kwargs):\n",
        "  mfcc = _mfcc(audio, samplerate=samplerate, numcep=n_features, **kwargs)\n",
        "  return mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "do9fjSpBSkj3",
        "outputId": "7605806e-ef85-4602-ea4b-02f1236d0add"
      },
      "source": [
        "# pcm 데이터 불러오기\n",
        "\n",
        "# data_dir : pcm directory path\n",
        "data_dir = \"../\"\n",
        "# data_dir = \"C:/Users/sooki/Desktop/data/001.일반남녀/001.일반남녀/성인남녀_001_A_001_M_KHI00_24_수도권_녹음실\"\n",
        "\n",
        "pcm_file = []\n",
        "for i in os.listdir(data_dir):\n",
        "    if 'PCM' in i:\n",
        "        pcm_file.append(data_dir + \"/\" + i)\n",
        "pcm_file[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C:/Users/sooki/Desktop/data/001.일반남녀/001.일반남녀/성인남녀_001_A_001_M_KHI00_24_수도권_녹음실/성인남녀_001_A_001_M_KHI00_24_수도권_녹음실_00001.PCM',\n",
              " 'C:/Users/sooki/Desktop/data/001.일반남녀/001.일반남녀/성인남녀_001_A_001_M_KHI00_24_수도권_녹음실/성인남녀_001_A_001_M_KHI00_24_수도권_녹음실_00002.PCM',\n",
              " 'C:/Users/sooki/Desktop/data/001.일반남녀/001.일반남녀/성인남녀_001_A_001_M_KHI00_24_수도권_녹음실/성인남녀_001_A_001_M_KHI00_24_수도권_녹음실_00003.PCM']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qkhkMA6Skj4"
      },
      "source": [
        "## pcm -> wav 파일변환 \n",
        "\n",
        "def pcm2wav(pcm_file, wav_file, channels=1, bit_depth=16, sampling_rate=16000):\n",
        "    if bit_depth %8 != 0:\n",
        "        raise ValueError(\"bit_depth\"+str(bit_depth)+\"must be a multiple of 8\")\n",
        "        \n",
        "    with open(pcm_file, 'rb') as opened_pcm_file:\n",
        "        pcm_data = opened_pcm_file.read()\n",
        "        \n",
        "        obj2write = wave.open(wav_file, 'wb')\n",
        "        obj2write.setnchannels(channels)\n",
        "        obj2write.setsampwidth(bit_depth//8)\n",
        "        obj2write.setframerate(sampling_rate)\n",
        "        obj2write.writeframes(pcm_data)\n",
        "        obj2write.close\n",
        "        \n",
        "        \n",
        "wav_file = [i.replace('PCM', 'wav') for i in pcm_file]\n",
        "for pcm, wav in zip(sound_file, wav_file):\n",
        "    pcm2wav(pcm, wav, 1, 16, 16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PBGWujiSkj4"
      },
      "source": [
        "# pcm2text 전사 텍스트 추출 리스트\n",
        "labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY5SEMLtSkj5"
      },
      "source": [
        "# o : pcm2text 파일 경로\n",
        "# pcm2text가 여러 가지 라면 경로를 바꿔가며 append 한다. \n",
        "\n",
        "o = open(\"../\", \"r\")\n",
        "# o = open(\"C:/Users/sooki/Desktop/data/002.노인남녀(시니어)/002.노인남녀(시니어)/000.PCM2TEXT/2020_시니어_학습DB_PCM2TEXT.list\", 'r', encoding='cp949') \n",
        "\n",
        "k = o.readlines()\n",
        "for i in k:\n",
        "    index = i.index('PCM')\n",
        "    string = i[index+4 : -1]\n",
        "    labels.append(string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyx7K3BgSkj5"
      },
      "source": [
        "#텍스트 정제 (특수기호 제거)\n",
        "\n",
        "for i, document in enumerate(labels):\n",
        "    document = re.sub(r'[.,!?\"\\':;~()…]', '', document) #특수기호 제거, 정규 표현식\n",
        "    labels[i] = document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atj_d2SoSkj6"
      },
      "source": [
        "# 띄어쓰기, 맞춤법\n",
        "\n",
        "a = '.'.join(labels)\n",
        "take1 = spacing(a)\n",
        "b = take1.split('.')\n",
        "c = '.'.join(b)\n",
        "\n",
        "spelled_sent = spell_checker.check(c)\n",
        "take2 = spelled_sent.checked\n",
        "take2=spell_checker.check(b)\n",
        "\n",
        "len_t=int(len(take2))\n",
        "text=[]\n",
        "for i in range(0,len_t):\n",
        "    text.append(take2[i][2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMyW00ywSkj6"
      },
      "source": [
        "# 데이터 생성\n",
        "\n",
        "def load_data(wav_file, text):\n",
        "    # 오디오 데이터 전처리\n",
        "    preprocess_audio = []\n",
        "    for audio in wave_file:\n",
        "        wav, sr = librosa.load(audio)\n",
        "        m = mfcc(wav, samplerate=sr, n_features=13)\n",
        "        pre_audio.append(m)\n",
        "    \n",
        "    # 텍스트 전처리\n",
        "    pre_text = []\n",
        "    for char in text:\n",
        "        pre = preprocess(char)\n",
        "        pre_text.append(pre)\n",
        "    \n",
        "    return (pre_audiio, pre_text)\n",
        "\n",
        "\n",
        "data = load_data(wav_file, text)\n",
        "data = list(filter(lambda x: x[0] is not None,data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M-Hp4vMSkj7",
        "outputId": "1b922200-4ed1-43bb-f022-6e06f7fe508b"
      },
      "source": [
        "# 하이퍼 파라메터 설정\n",
        "\n",
        "params = tf.contrib.training.HParams(\n",
        "    learning_rate=0.002,\n",
        "    n_classes=54,\n",
        "    train_steps=10,\n",
        "    min_eval_frequency=100,\n",
        "    use_fp16=False,\n",
        "    num_filters=5,\n",
        "    temporal_stride=1,\n",
        "    keep_prob=0.5,\n",
        "    batch_size=100,\n",
        "    num_hidden=50,\n",
        "    num_rnn_layers=3,\n",
        "    rnn_type='uni-dir'\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TPHFTkKSkj8"
      },
      "source": [
        "# 텍스트 인코딩/디코딩 함수\n",
        "\n",
        "NUM_CLASSES = 54\n",
        "feat_len = 13\n",
        "n_features = 50\n",
        "\n",
        "ctc_labels = LABELS\n",
        "labels = [\" \"] + ctc_labels\n",
        "labels\n",
        "\n",
        "_encode_map = {c: i for i, c in enumerate(labels)}\n",
        "_decode_map = labels + [\"\"]\n",
        "\n",
        "\n",
        "def encode(texts):\n",
        "  indices = []\n",
        "  values = []\n",
        "  for index, text in enumerate(texts):\n",
        "    indices.extend(zip([index] * len(text), range(len(text))))\n",
        "    values.extend(map(lambda c: _encode_map[c], text))\n",
        "  indices = np.asarray(indices, dtype=np.int64)\n",
        "  values = np.asarray(values, dtype=np.int32)\n",
        "  shape = np.asarray([len(texts), np.asarray(indices).max(0)[1] + 1],dtype=np.int64)\n",
        "  return indices, values, shape\n",
        "\n",
        "def decode(sequences):\n",
        "  \"\"\"Decode CTC output to texts.\"\"\"\n",
        "  return list(map(lambda s: \"\".join(map(lambda c: _decode_map[c], s)), sequences))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Dmk3htSkj9"
      },
      "source": [
        "# acoustic model (음향모델)\n",
        "\n",
        "def acoustic_model(feats, seq_len, targets, params, is_train):\n",
        "    with tf.variable_scope('conv1') as scope:\n",
        "\n",
        "        \n",
        "        output_dropout_prob=0.3\n",
        "        state_dropout_prob=0.3\n",
        "        output_keep_prob = tf.cond(is_train, lambda: 1.0-output_dropout_prob, lambda: 1.0)\n",
        "        state_keep_prob = tf.cond(is_train, lambda: 1.0-state_dropout_prob, lambda: 1.0)\n",
        "        \n",
        "        kernel = tf.get_variable('weights',\n",
        "            shape=[10, 1, 1, params.num_filters],initializer=\\\n",
        "            tf.contrib.layers.variance_scaling_initializer(factor=2.0,\n",
        "                                                       mode='FAN_IN',\n",
        "                                                       uniform=False,\n",
        "                                                       seed=None,\n",
        "                                                       dtype= tf.float32), dtype=tf.float32)\n",
        "\n",
        "        feats = tf.expand_dims(feats, dim=-1)\n",
        "        conv = tf.nn.conv2d(feats, kernel,\n",
        "                            [1, params.temporal_stride, 1, 1],padding='SAME')\n",
        "        # conv = tf.nn.atrous_conv2d(feats, kernel, rate=2, padding='SAME')\n",
        "        biases = tf.get_variable('biases', [params.num_filters],\n",
        "                                  initializer=tf.constant_initializer(0),\n",
        "                                  dtype=tf.float32)\n",
        "        bias = tf.nn.bias_add(conv, biases)\n",
        "        conv1 = tf.nn.relu(bias, name=scope.name)\n",
        "        conv1_drop = tf.nn.dropout(conv1, output_keep_prob)\n",
        "\n",
        "    # recurrent layers\n",
        "    with tf.variable_scope('rnn') as scope:\n",
        "        \n",
        "        rnn_input = tf.reshape(conv1_drop, [params.batch_size, -1,feat_len*params.num_filters])\n",
        "\n",
        "        \n",
        "        \n",
        "        cells = [tf.contrib.rnn.LSTMCell(100) for _ in range(2)]\n",
        "        cells = [tf.contrib.rnn.DropoutWrapper(cell,\n",
        "                                           output_keep_prob=output_keep_prob,\n",
        "                                           state_keep_prob=state_keep_prob,\n",
        "                                           variational_recurrent=True,\n",
        "                                           dtype=tf.float32)\n",
        "             for cell in cells]\n",
        "        outputs, _ = tf.nn.bidirectional_dynamic_rnn(*cells, rnn_input, seq_len, dtype=tf.float32)\n",
        "        outputs = tf.reshape(tf.concat(outputs, 2), [-1, 2 * 100])\n",
        "        \n",
        "        \n",
        "        # Fully connected layer\n",
        "        W = tf.Variable(tf.truncated_normal([2 * 100, params.n_classes], stddev=0.1))\n",
        "        b = tf.Variable(tf.constant(0., shape=[params.n_classes]))\n",
        "        logits = tf.transpose(tf.reshape(tf.matmul(outputs, W) + b, [tf.shape(feats)[0], -1, params.n_classes]), (1, 0, 2))     \n",
        "\n",
        "        decoded,_=tf.nn.ctc_beam_search_decoder(logits, seq_len, beam_width=100)\n",
        "        with tf.name_scope(\"Loss\"):\n",
        "            ctc = tf.reduce_mean(tf.nn.ctc_loss(targets,logits,seq_len,ignore_longer_outputs_than_inputs=True))\n",
        "        \n",
        "        with tf.name_scope(\"ler\"):\n",
        "            ler=tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32), targets))\n",
        "        with tf.name_scope(\"Decoded\"):\n",
        "            decoded=tf.sparse_tensor_to_dense(decoded[0],-1)\n",
        "        \n",
        "\n",
        "\n",
        "        return ctc, decoded, ler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPB57qmuSkj-"
      },
      "source": [
        "def feed(data, istrain):\n",
        "    t1 = data[0]\n",
        "    t2 = data[1]\n",
        "\n",
        "    text = encode(t2)\n",
        "       \n",
        "    input_len_feed = np.asarray(list(map(len, t1)), np.int32)\n",
        "    inputs_feed = np.zeros((len(t1),\n",
        "                             max(input_len_feed),\n",
        "                             feat_len),\n",
        "                            np.float32)\n",
        "    for i, l in enumerate(input_len_feed):\n",
        "        inputs_feed[i, :l, :] = t1[i]\n",
        "    return {inputs: inputs_feed, \n",
        "            input_len: input_len_feed,\n",
        "            output: text,\n",
        "            is_train:istrain}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_p8ErVwSkj-"
      },
      "source": [
        "def batch_generator(data, batch_size, idx=0, num_workers=1, bin_size=100):\n",
        "  bin_num = len(data[0]) // 100\n",
        "  tmp = []\n",
        "  bin_idx = 0\n",
        "  i = data[0]\n",
        "  j = data[1]\n",
        "  for _ in range(bin_num):\n",
        "    t0 = []\n",
        "    for k, l in zip(i[bin_idx:bin_idx+bin_size], j[bin_idx:bin_idx+bin_size]): \n",
        "        t0.append([k, l])\n",
        "        tmp.append(t0)\n",
        "    bin_idx += bin_size\n",
        "  order = list(range(0, len(i), batch_size))\n",
        "  \n",
        "  shuffle(order)\n",
        "    \n",
        "  data = sum(tmp, [])\n",
        "  data_batch = []\n",
        "  for i in order:\n",
        "      if i % num_workers == idx:\n",
        "           data_batch.append(list(zip(*data[i:(i+batch_size)])))\n",
        "  return data_batch         \n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_efyRuSSkj_"
      },
      "source": [
        "_random.seed(29520)\n",
        "        \n",
        "n_train = int(len(data[0]) * 0.85/params.batch_size) * params.batch_size\n",
        "# n_valid=n_train+int(len(data[0])*0.01)\n",
        "n_valid = 100\n",
        "# n_test=n_valid+int(len(data[0])*0.01)\n",
        "n_test = 100\n",
        "\n",
        "test_set=data[n_train+n_valid:n_train+n_valid+n_test]\n",
        "valid_set=data[n_train+n_valid:n_valid]\n",
        "batchs = {\n",
        "      \"train\": batch_generator((data[0][:n_train], data[1][:n_train]) ,params.batch_size),\n",
        "      \"valid\": batch_generator((data[0][n_train:n_train+n_valid],data[1][n_train:n_train+n_valid]), params.batch_size),\n",
        "      \"test\": batch_generator((data[0][800:900], data[1][800:900]), params.batch_size)\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUfswXSXSkj_"
      },
      "source": [
        "with tf.device(tf.train.replica_device_setter(worker_device=\"/gpu:0\",\n",
        "                                                 ps_device=\"/cpu:0\",\n",
        "                                                 ps_tasks=1)):\n",
        "\n",
        "\n",
        "  # with tf.Graph().as_default():   \n",
        "        tf.reset_default_graph () \n",
        "        inputs = tf.placeholder(tf.float32, [None, None,feat_len])\n",
        "        input_len = tf.placeholder(tf.int32, [None])\n",
        "        output = tf.sparse_placeholder(tf.int32)\n",
        "        is_train = tf.placeholder(tf.bool)\n",
        "        cost, deco, ler=acoustic_model(inputs, input_len, output, params, is_train)\n",
        " \n",
        "\n",
        "        tf.summary.scalar(\"CTC\", cost)\n",
        "        tf.summary.scalar(\"LER\", ler)\n",
        "        summary = tf.summary.merge_all()\n",
        "        global_step = tf.train.get_or_create_global_step()\n",
        "\n",
        "        train_op = tf.train.AdamOptimizer(params.learning_rate).minimize(cost, global_step,name=\"train_op\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cquzyF7GSkkA"
      },
      "source": [
        "# train data set 학습 / validation data set 검증\n",
        "\n",
        "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True),\n",
        "                         allow_soft_placement=True,\n",
        "                         log_device_placement=True)\n",
        "model_path =  \"../model\"\n",
        "writers = {phase: tf.summary.FileWriter(path.join(\"./logs\", phase)) for phase in [\"train_sen2\", \"valid_sen2\",\"test_sen2\"]}\n",
        "\n",
        "\n",
        "\n",
        "with tf.Session(config=config) as sess:\n",
        "  try:\n",
        "      saver = tf.train.Saver(tf.all_variables(),max_to_keep=500)  \n",
        "      saver.restore(sess, tf.train.latest_checkpoint(\"../check\"))\n",
        "      global_step=tf.train.get_global_step()\n",
        "      train_op = tf.get_default_graph().get_tensor_by_name(\"train_op:0\")\n",
        "      step = sess.run(global_step)\n",
        "  except ValueError:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      step=0\n",
        "\n",
        "  \n",
        "  for i in range(10):\n",
        "        cost_total=ler_total=0\n",
        "        print(\"===== TRAINING =====\")\n",
        "        \n",
        "        for j in range(int(n_train/params.batch_size)):\n",
        "            print(j)\n",
        "            step,trainsum,_ = sess.run([global_step,summary,train_op], feed_dict=feed(batchs[\"train\"][j], True))\n",
        "            writers[\"train_sen2\"].add_summary(trainsum, step)\n",
        "        for k in range(int(n_valid/params.batch_size)):\n",
        "          print(k)\n",
        "          vcost,vler = sess.run([cost,ler], feed_dict=feed(batchs[\"valid\"][k], False))\n",
        "          print(vcost)\n",
        "          print(vler)\n",
        "          \n",
        "          saver.save(sess, model_path, global_step=i)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbsE_tarSkkA"
      },
      "source": [
        "# test data set 평가\n",
        "\n",
        "with tf.Session(config=config) as sess: \n",
        "    print(\"===== TESTING =====\")\n",
        "    for l in range(int(n_test/params.batch_size)):\n",
        "        testsum,str_decoded,test_cost, test_ler=sess.run([summary, deco, cost, ler], feed_dict=feed(batchs[\"test\"][l], False))\n",
        "        writers[\"test_sen2\"].add_summary(testsum)\n",
        "        print(\"LER: %f\" %vler)\n",
        "        for ss in zip(senior_text[:100], decode(str_decoded)):\n",
        "            print(\"    Original: %s\" % ss[0])\n",
        "            print(\"    Decoded:  %s\" % ss[1])\n",
        " \n",
        "\n",
        "    print(\"Run 'tensorboard --logdir=%s'\"%writers[\"train_sen2\"].get_logdir())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXke0-_2SkkB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ8w6zBDSkkB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ivzr1shSkkB"
      },
      "source": [
        "# pcm 파일 이름 추출\n",
        "\n",
        "# o : pcm2list 경로\n",
        "o = open(\"../\", \"r\")\n",
        "# o = open(\"C:/Users/sooki/Desktop/data/002.노인남녀(시니어)/002.노인남녀(시니어)/000.PCM2TEXT/2020_시니어_학습DB_PCM2TEXT.list\", 'r', encoding='cp949') \n",
        "\n",
        "k = o.readlines()\n",
        "file = []\n",
        "for i in k:\n",
        "    l = i.split('\\t')\n",
        "    string = l[0]\n",
        "    file.append(string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgZOcmleSkkB"
      },
      "source": [
        "# 인식결과 txt 파일 생성\n",
        "f = open('recognition.txt', 'w', newline = '') \n",
        "for i, j in zip(file, decoded(str_decoded)):\n",
        "    f.write('{0}\\t{1}\\n'.format(i, j))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M82ggHpPSkkC"
      },
      "source": [
        "# 전사결과 txt 파일 생성\n",
        "g = open('text.txt', 'w', newline = '') \n",
        "for i, j in zip(file, text):\n",
        "    g.write('{0}\\t{1}\\n'.format(i, j))\n",
        "g.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}